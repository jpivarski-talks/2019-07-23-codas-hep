{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "# Accelerating Python\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "### 1. Vertical scaling (making a single thread faster)\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Apart from clever algorithms, the speed of a program is determined by how laden it is with work unrelated to its main task.</p>\n",
    "\n",
    "<center><img src=\"img/swallows-coconut.jpg\" width=\"50%\"></center>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Python is slower than C because of dynamic type checking, garbage collection, everything-is-a-hashtable, pointer chasing, string equality checks...</p>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 1.25em\">Compare to Java, which has garbage collection but not dynamic type checking, and C, which has neither (on a variety of benchmark algorithms).</p>\n",
    "\n",
    "<img src=\"img/benchmark-games.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">If you care about speed <i>more than</i> ease of development, use C or C++ (or Rust!).</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">If you want to use Python for all of its conveniences—dynamic type checking, garbage collection, everything-is-a-hashtable, interactive development and debugging—and need to speed up a critical section, there are ways to do it.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">But you have to give up Python's dynamism <i>in that section.</i></p>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some wacky things you can do to types and objects in Python:\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "p = Point(1, 2)\n",
    "\n",
    "# dynamically add an attribute to an instance (attributes are really a hashtable)\n",
    "p.z = 3\n",
    "\n",
    "# dynamically add a method to a class (class is a hashtable of functions)\n",
    "Point.mag2 = lambda self: self.x**2 + self.y**2 + self.z**2\n",
    "p.mag2()\n",
    "\n",
    "# dynamically add a method to an instance (differs only in assigning \"self\")\n",
    "p.mag = (lambda self: self.mag2()**0.5).__get__(p)\n",
    "p.mag()\n",
    "\n",
    "class Pointy(Point):\n",
    "    def __repr__(self):\n",
    "        return \"Pointy({0}, {1})\".format(self.x, self.y)\n",
    "\n",
    "# dynamically change the class of an object (type is just an attribute)\n",
    "p.__class__ = Pointy\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's because in Python, this:\n",
    "\n",
    "print()\n",
    "print(Point(1, 2))\n",
    "\n",
    "# is not fundamentally different from this:\n",
    "\n",
    "print()\n",
    "print({\"x\": 1, \"y\": 2})\n",
    "\n",
    "# as you can see by this:\n",
    "\n",
    "print()\n",
    "print(Point(1, 2).__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">As a statically compiled program, Python has only one data type, <tt>PyObject*</tt> with a pointer to its runtime type, which is yet another <tt>PyObject*</tt>.</p>\n",
    "\n",
    "<center><img src=\"img/pyobject.png\" width=\"50%\"></center>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">That gives us the flexibility to do all the wacky things on the previous slide, but at a runtime cost of checking those types <i>every time they are used.</i></p>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is an integer\n",
    "x = 0\n",
    "\n",
    "for i in range(1000000):\n",
    "    # in the millionth step, replace x with a string\n",
    "    if i == 999999:\n",
    "        x = \"hello\"\n",
    "    # do an operation on x that only works for integers\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def f():\n",
    "    x = 0\n",
    "    for i in range(1000000):\n",
    "        # in the millionth step, replace x with a string\n",
    "        if i == 999999:\n",
    "            x = \"hello\"\n",
    "        # do an operation on x that only works for integers\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "\n",
    "ROOT.gInterpreter.Declare(\"\"\"\n",
    "int f() {\n",
    "    int x = 0;\n",
    "    for (int i = 0; i < 1000000; i++) {\n",
    "        // in the millionth step, replace x with a string\n",
    "        if (i == 999999) {\n",
    "            x = \"hello\";\n",
    "        }\n",
    "        // do an operation on x that only works for integers\n",
    "        x += 1;\n",
    "    }\n",
    "    return x;\n",
    "}\"\"\")\n",
    "\n",
    "ROOT.f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">My unsurprising, conventional answer to <b>\"how do I make it fast?\"</b></p>\n",
    "\n",
    "<ol>\n",
    "    <li style=\"font-size: 1.25em; margin-bottom: 0.75em\">Determine all data types statically: i.e. one variable ↔ one type and all values in a list/array have the same type.\n",
    "    <li style=\"font-size: 1.25em\">Take advantage of the static types by converting the program into machine code: i.e. verify those types and generate code without runtime type-checks.\n",
    "</ol>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center\"><b>We usually call this \"compiling.\"</b></p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>But:</b> \"compiling\" does not necessarily mean \"rewrite in C or C++.\"</p>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size: 1.25em; margin-bottom: 0.75em\">Any language can be compiled.\n",
    "    <li style=\"font-size: 1.25em; margin-bottom: 0.75em\">Compilation does not need to be a separate phase from running the program.\n",
    "    <li style=\"font-size: 1.25em; margin-bottom: 0.75em\">The compiled section can be as little or as much as you want.\n",
    "    <li style=\"font-size: 1.25em; margin-bottom: 0.75em\">If you're using Python to organize your analysis, focus only on the part that needs to be fast. <i>Which part scales with the number of events?</i>\n",
    "</ul>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<center><img src=\"img/numba-logo.png\" width=\"25%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\">Numba is a just-in-time compiler of Python code.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def mag(xarray, yarray):\n",
    "    out = numpy.empty(min(len(xarray), len(yarray)))\n",
    "    \n",
    "    for i in range(len(out)):\n",
    "        out[i] = numpy.sqrt(xarray[i]**2 + yarray[i]**2)\n",
    "    \n",
    "    return out\n",
    "\n",
    "mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.arange(1000000, dtype=numpy.int32)\n",
    "b = numpy.arange(1000000, dtype=numpy.int64)\n",
    "\n",
    "gap = \",\\n                        \"\n",
    "print(f\"mag.overloads.keys() = [{gap.join(str(x) for x in mag.overloads.keys())}]\")\n",
    "print(f\"\\nmag(a, a).sum()      = {mag(a, a).sum()}\")\n",
    "print(f\"mag.overloads.keys() = [{gap.join(str(x) for x in mag.overloads.keys())}]\")\n",
    "print(f\"\\nmag(a, b).sum()      = {mag(a, b).sum()}\")\n",
    "print(f\"mag.overloads.keys() = [{gap.join(str(x) for x in mag.overloads.keys())}]\")\n",
    "print(f\"\\nmag(b, b).sum()      = {mag(b, b).sum()}\")\n",
    "print(f\"mag.overloads.keys() = [{gap.join(str(x) for x in mag.overloads.keys())}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Numba compiles a <a href=\"https://numba.pydata.org/numba-doc/dev/reference/pysupported.html\" target=\"_blank\">subset of the Python language</a> and a <a href=\"https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html\" target=\"_blank\">subset of Numpy functions</a> to machine code (through LLVM).</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">It also sets up conversions between Python/Numpy and the compiled code.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">A good way to use it: develop in Python because it's easy, eliminate dynamic features from the part that needs to be fast, and try <tt>@numba.jit</tt> until successful.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba has a particular affinity for Numpy (and an unfortunate name).\n",
    "#\n",
    "# Most of the type declarations (int this, float that) come from Numpy dtypes.\n",
    "\n",
    "# numba.vectorize lets you define a Numpy ufunc from a scalars → scalar function:\n",
    "@numba.vectorize\n",
    "def mag(x, y):\n",
    "    return numpy.sqrt(x**2 + y**2)\n",
    "\n",
    "mag(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "<center><img src=\"img/root-logo.png\" width=\"50%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\">ROOT does many things, but one of them is <i>automatically</i> binding C++ to Python.</p>\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp -d\n",
    "\n",
    "//# Of course, you can also write the part that needs to be fast in C++.\n",
    "\n",
    "void mag(int n, double* xarray, double* yarray, double* out) {\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        out[i] = sqrt(xarray[i]*xarray[i] + yarray[i]*yarray[i]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "yarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "out = numpy.empty(1000000, dtype=numpy.float64)\n",
    "\n",
    "ROOT.mag(len(out), xarray, yarray, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">After you <tt>import ROOT</tt>,</p>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size: 1.25em\"><tt>%%cpp</tt> at the top of a Jupyter cell evaluates as a line of C++ ROOT,\n",
    "    <li style=\"font-size: 1.25em\"><tt>%%cpp -d</tt> at the top of a Jupyter cell defines a C++ function,\n",
    "    <li style=\"font-size: 1.25em\"><tt>ROOT.gInterpreter.ProcessLine</tt> in Python evaluates a line of C++ ROOT,\n",
    "    <li style=\"font-size: 1.25em\"><tt>ROOT.gInterpreter.Declare</tt> in Python defines a C++ function,\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">and PyROOT lets you call C++ functions from Python.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"img/03-cheat-sheet.png\" width=\"100%\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can't redefine C++ functions, which makes interactive work difficult.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ROOT.gInterpreter.Declare(r\"\"\"\n",
    "\n",
    "    double cpp_func(double x) {\n",
    "        return x*x;\n",
    "    }\n",
    "\n",
    "\"\"\")\n",
    "cpp_func = ROOT.cpp_func\n",
    "\n",
    "cpp_func(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can't redefine C++ functions, which makes interactive work difficult.\n",
    "# \n",
    "# Here's a way to make a redefinable function:\n",
    "\n",
    "pyname = \"cpp_func\"\n",
    "cppname = pyname + \"_%d\" % sum(1 if x.startswith(pyname) else 0 for x in dir(ROOT))\n",
    "ROOT.gInterpreter.Declare(r\"\"\"\n",
    "\n",
    "    double \"\"\" + cppname + r\"\"\"(double x) {\n",
    "        return x*x;\n",
    "    }\n",
    "\n",
    "\"\"\")\n",
    "exec(f\"{pyname} = ROOT.{cppname}\")\n",
    "\n",
    "cpp_func(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, you need to be very careful about data types because ROOT does not\n",
    "# read them off of Numpy arrays.\n",
    "\n",
    "if not hasattr(ROOT, \"assumes_double\"):\n",
    "    ROOT.gInterpreter.Declare(\"\"\"\n",
    "void assumes_double(int n, double* xarray, double* out) {\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        out[i] = xarray[i]*xarray[i];\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "xarray = numpy.arange(10, dtype=numpy.float64)     # change to int64\n",
    "out = numpy.empty(10, dtype=numpy.float64)         # change to int64\n",
    "\n",
    "ROOT.assumes_double(10, xarray, out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're sending arrays of data to and from ROOT, you should probably let\n",
    "# ROOT control the type, size, and memory of those arrays as C++ std::vector.\n",
    "\n",
    "# a_vector = std::vector<double>(1000000);\n",
    "a_vector = ROOT.std.vector(\"double\")(1000000)\n",
    "\n",
    "# a_array only WRAPS it as a Numpy array.\n",
    "a_array = numpy.asarray(a_vector)\n",
    "\n",
    "# Assigning to this Numpy array changes the memory owned by the std::vector.\n",
    "a_array[:] = numpy.arange(1000000, dtype=numpy.float64)\n",
    "\n",
    "# See?\n",
    "list(a_vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(ROOT, \"verifies_double\"):\n",
    "    ROOT.gInterpreter.Declare(\"\"\"\n",
    "std::vector<double> verifies_double(std::vector<double> xarray) {\n",
    "    std::vector<double> out;\n",
    "    out.reserve(xarray.size());\n",
    "    \n",
    "    for (int i = 0; i < xarray.size(); i++) {\n",
    "        out.push_back(xarray[i]*xarray[i]);\n",
    "    }\n",
    "    \n",
    "    return out;    // safe because of C++ move semantics\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "a_vector = ROOT.std.vector(\"double\")(1000000)    # change to \"int\"\n",
    "a_array = numpy.asarray(a_vector)\n",
    "a_array[:] = numpy.arange(1000000, dtype=numpy.float64)\n",
    "\n",
    "b_vector = ROOT.verifies_double(a_vector)\n",
    "b_array = numpy.asarray(b_vector)\n",
    "\n",
    "b_array[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Reminder:</b> a Numpy object is a Python object that <i>points to</i> memory, maybe someone else's memory.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/numpy-memory-layout.png\" width=\"75%\"></center>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Numpy object of the array does not \"own\" the data, so it does not try to\n",
    "# delete it when it gets garbage collected.\n",
    "\n",
    "print(f\"a_array.flags.owndata = {a_array.flags.owndata}\")\n",
    "\n",
    "del a_array\n",
    "\n",
    "# Make sure the garbage collector deletes the Numpy object.\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# The std::vector and its data still exist.\n",
    "print(f\"\\na_vector[:10]         = {[a_vector[i] for i in range(10)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But if you delete it on the C++ side, the Numpy object does not know!\n",
    "b_vector.clear()\n",
    "# b_vector.shrink_to_fit()\n",
    "print(f\"b_array[:10] = {b_array[:10]}\")\n",
    "\n",
    "b_vector.push_back(100)\n",
    "print(f\"b_array[:10] = {b_array[:10]}\")\n",
    "\n",
    "b_vector.push_back(200)\n",
    "print(f\"b_array[:10] = {b_array[:10]}\")\n",
    "\n",
    "b_vector.push_back(300)\n",
    "print(f\"b_array[:10] = {b_array[:10]}\")\n",
    "\n",
    "b_vector.push_back(400)\n",
    "print(f\"b_array[:10] = {b_array[:10]}\")\n",
    "\n",
    "b_vector.push_back(500)\n",
    "print(f\"b_array[:10] = {b_array[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "<center><img src=\"img/pybind11-logo.png\" width=\"50%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\">pybind11 <i>manually</i> binds C++ to Python, suitable for production code.</p>\n",
    "\n",
    "<p style=\"font-size: 1em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\"><i>(I just want you to be aware of it.)</i></p>\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"cpp_calculate.cpp\", \"w\").write(r\"\"\"\n",
    "#include <pybind11/pybind11.h>\n",
    "#include <pybind11/numpy.h>\n",
    "void cpp_func(pybind11::array_t<double> inarray, pybind11::array_t<double> outarray) {\n",
    "    size_t N = inarray.request().size;\n",
    "    double *in = (double*)inarray.request().ptr;\n",
    "    double *out = (double*)outarray.request().ptr;\n",
    "    for (size_t i = 0; i < N; i++) {\n",
    "        out[i] = in[i] * in[i];\n",
    "    }\n",
    "}\n",
    "PYBIND11_MODULE(cpp_calculate, m) {\n",
    "    m.def(\"cpp_func\", &cpp_func, \"\");\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "import os\n",
    "os.system(r\"c++ -Wall -shared -std=c++11 -fPIC -O3 `python -m pybind11 --includes` cpp_calculate.cpp -o cpp_calculate`python3-config --extension-suffix`\")\n",
    "\n",
    "import cpp_calculate\n",
    "inarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "outarray = numpy.empty(1000000, dtype=numpy.float64)\n",
    "cpp_calculate.cpp_func(inarray, outarray)\n",
    "outarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "<center><img src=\"img/cython-logo.png\" width=\"35%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\">Cython lets you <i>mix</i> C++ and Python code in a half-and-half syntax.</p>\n",
    "\n",
    "<p style=\"font-size: 1em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\"><i>(I just want you to be aware of it.)</i></p>\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus -c-O3 -a\n",
    "import cython, numpy\n",
    "cimport numpy\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def cython_calculate(inarray, outarray):\n",
    "    cdef numpy.ndarray[numpy.float64_t, ndim=1, mode=\"c\"] inarray_raw = inarray\n",
    "    cdef numpy.ndarray[numpy.float64_t, ndim=1, mode=\"c\"] outarray_raw = outarray\n",
    "    cdef int N = len(inarray)\n",
    "    for i in range(N):\n",
    "        outarray_raw[i] = inarray_raw[i] * inarray_raw[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "outarray = numpy.empty(1000000, dtype=numpy.float64)\n",
    "\n",
    "cython_calculate(inarray, outarray)\n",
    "\n",
    "outarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "### 2. Horizontal scaling (distributing the work across threads)\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<center><img src=\"img/dask-logo.png\" width=\"25%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\">Dask is a parallel processing framework for Numpy arrays.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code computes NOTHING.\n",
    "\n",
    "import dask.array\n",
    "\n",
    "def compute(xarray, yarray):\n",
    "    return numpy.sqrt(xarray**2 + yarray**2)\n",
    "\n",
    "xarray = dask.array.from_array(numpy.arange(1000000, dtype=numpy.float64), 100000)\n",
    "yarray = dask.array.from_array(numpy.arange(1000000, dtype=numpy.float64), 100000)\n",
    "\n",
    "outarray = compute(xarray, yarray)\n",
    "outarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following computes it on all cores.\n",
    "\n",
    "outarray.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is \"outarray\"? It's a description of work to be done.\n",
    "\n",
    "outarray.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask-schedulers and dask-workers could be running remotely...\n",
    "\n",
    "os.system(r\"dask-scheduler &\")\n",
    "os.system(r\"dask-worker --nthreads 8 127.0.0.1:8786 &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.distributed\n",
    "\n",
    "maybe_remote = dask.distributed.Client(\"127.0.0.1:8786\")\n",
    "maybe_remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can run those same array operations anywhere, distributed by its \"chunks.\"\n",
    "\n",
    "outarray.compute(scheduler=maybe_remote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!killall dask-scheduler dask-worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem with Dask... do you remember the \"compute a fractal\" example?\n",
    "\n",
    "def run_dask(height, width, maxiterations=20, hchunks=3, vchunks=4):\n",
    "    chunked = lambda a: dask.array.from_array(a, chunks=(height // hchunks, width // vchunks))\n",
    "    y, x = numpy.ogrid[-1:0:height*1j, -1.5:0:width*1j]\n",
    "    c = chunked(x + y*1j)\n",
    "    fractal = chunked(numpy.full(c.shape, maxiterations, dtype=numpy.int32))\n",
    "    z = c\n",
    "    for i in range(maxiterations):\n",
    "        z = z**2 + c                                            # applying z → z² + c\n",
    "        diverged = numpy.absolute(z) > 2                        # |z| > 2 is \"divergence\"\n",
    "        diverging_now = diverged & (fractal == maxiterations)   # some are already done\n",
    "        fractal[diverging_now] = i                              # just set the new ones\n",
    "        z[diverged] = 2                                         # clamp diverged at 2\n",
    "    return fractal\n",
    "\n",
    "run_dask(1600, 2400, maxiterations=1, hchunks=3, vchunks=4).visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are too many little tasks!\n",
    "# \n",
    "# Numba is not only good for compiling a complex function, it can also combine\n",
    "# operations to hide them from Dask, simplifying the graph.\n",
    "\n",
    "# Make a Numpy ufunc...\n",
    "@numba.vectorize([numba.int32(numba.complex128, numba.int32)])\n",
    "def run_numba_ufunc(c, maxiterations):\n",
    "    z = c\n",
    "    for i in range(maxiterations):\n",
    "        z = z**2 + c\n",
    "        if abs(z) > 2:\n",
    "            return i\n",
    "    return maxiterations\n",
    "\n",
    "# Dask recognizes Numpy ufuncs...\n",
    "def run_dask_numba(height, width, maxiterations=20, hchunks=3, vchunks=4):\n",
    "    chunked = lambda a: dask.array.from_array(a, chunks=(height // hchunks, width // vchunks))\n",
    "    y, x = numpy.ogrid[-1:0:height*1j, -1.5:0:width*1j]\n",
    "    return run_numba_ufunc(chunked(x + y*1j), maxiterations)\n",
    "\n",
    "run_dask_numba(1600, 2400, maxiterations=20, hchunks=3, vchunks=4).visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">This is a good example of two libraries not explicitly talking to each other, but both speaking the common language of Numpy ufuncs.</p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 1.25em\">Applying all the acceleration methods to the same <a href=\"misc-fractal.ipynb\">fractal example</a>:</p>\n",
    "\n",
    "| Method                                     | time (ns/px) | speedup |\n",
    "|:-------------------------------------------|-------------:|--------:|\n",
    "| Pure Python                                        | 12000   |    1× |\n",
    "| Vectorized Numpy                                   |   368   |   30× |\n",
    "| Vectorized CuPy (run on GPU)                       |    81   |  150× |\n",
    "| Compiled by Numba                                  |   136   |   90× |\n",
    "| Compiled & parallelized by Numba                   |    45   |  250× |\n",
    "| Compiled & run on GPU by Numba                     |     7.8 | 1500× |\n",
    "| Parallelized by Dask                               |   238   |   50× |\n",
    "| Parallelized by Dask, compiled by Numba            |    48   |  250× |\n",
    "| Partially rewritten in Cython (Python/C++ hybrid)  |  1485   |    8× |\n",
    "| Completely rewritten in Cython (pure C++)          |    99   |  120× |\n",
    "| Completely rewritten in pybind11 (pure C++)        |    98   |  120× |\n",
    "| Completely rewritten in ROOT (pure C++ with `-O0`) |   379   |   32× |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "### Multithreading/multiprocessing\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading                 # part of Python\n",
    "\n",
    "class Minion(threading.Thread):\n",
    "    def __init__(self, i, j, xarray, yarray, outarray):\n",
    "        super(Minion, self).__init__()\n",
    "        self.i, self.j = i, j\n",
    "        self.xarray, self.yarray, self.outarray = xarray, yarray, outarray\n",
    "\n",
    "    def run(self):\n",
    "        i, j, outarray = self.i, self.j, self.outarray\n",
    "        outarray[i:j] = numpy.sqrt(self.xarray[i:j]**2 + self.yarray[i:j]**2)\n",
    "\n",
    "xarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "yarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "outarray = numpy.empty(1000000, dtype=numpy.float64)\n",
    "\n",
    "minions = []\n",
    "for i, j in zip(range(0, 10), range(1, 10+1)):\n",
    "    minions.append(Minion(i*100000, j*100000, xarray, yarray, outarray))\n",
    "\n",
    "for minion in minions: minion.start()    # start all the threads\n",
    "for minion in minions: minion.join()     # wait for all the threads to finish\n",
    "\n",
    "outarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing, ctypes   # part of Python\n",
    "\n",
    "class Minion(multiprocessing.Process):\n",
    "    def __init__(self, i, j, xarray, yarray, outarray):\n",
    "        super(Minion, self).__init__()\n",
    "        self.i, self.j = i, j\n",
    "        self.xarray, self.yarray, self.outarray = xarray, yarray, outarray\n",
    "\n",
    "    def run(self):\n",
    "        i, j, outarray = self.i, self.j, numpy.frombuffer(self.outarray, numpy.float64)\n",
    "        outarray[i:j] = numpy.sqrt(self.xarray[i:j]**2 + self.yarray[i:j]**2)\n",
    "\n",
    "xarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "yarray = numpy.arange(1000000, dtype=numpy.float64)\n",
    "outarray = multiprocessing.RawArray(ctypes.c_double, 1000000)  # shared memory!\n",
    "\n",
    "minions = []\n",
    "for i, j in zip(range(0, 10), range(1, 10+1)):\n",
    "    minions.append(Minion(i*100000, j*100000, xarray, yarray, outarray))\n",
    "\n",
    "for minion in minions: minion.start()    # start all the threads\n",
    "for minion in minions: minion.join()     # wait for all the threads to finish\n",
    "\n",
    "numpy.frombuffer(outarray, dtype=numpy.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Why separate processes? Look up \"Global Interpreter Lock\" (GIL).</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Short story: a single Python process can be <i>concurrent</i>, but not <i>parallel</i>.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "(Longer story: compiled code like Numpy and Numba can release the GIL and truly run in parallel, but Python operations on the same arrays can act as a _barrier_. Only independent Python processes are completely unconstrained.)\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<center><img src=\"img/coffea-logo.png\" width=\"25%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center; margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px\">Coffea is a suite of Python tools for particle physics, including parallelization.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coffea.hist\n",
    "import coffea.processor\n",
    "\n",
    "class Minion(coffea.processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        self.histograms = coffea.processor.dict_accumulator(dict(\n",
    "            pt = coffea.hist.Hist(\"pt\", coffea.hist.Bin(\"pt\", \"pt\", 100, 0, 200)),\n",
    "            m = coffea.hist.Hist(\"m\", coffea.hist.Bin(\"m\", \"m\", 100, 0, 200))\n",
    "        ))\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self.histograms\n",
    "    def process(self, df):\n",
    "        out = self.accumulator.identity()\n",
    "        out[\"pt\"].fill(pt=numpy.sqrt((df[\"px1\"] + df[\"px2\"])**2 + (df[\"py1\"] + df[\"py2\"])**2))\n",
    "        out[\"m\"].fill(m=df[\"M\"])\n",
    "        return out\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "\n",
    "out = coffea.processor.run_uproot_job({\"signal\": [\"data/Zmumu.root\"]},\n",
    "    treename=\"events\", processor_instance=Minion(), executor=coffea.processor.futures_executor)\n",
    "\n",
    "coffea.hist.plot1d(out[\"pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in dir(coffea.processor) if x.startswith(\"run_\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
