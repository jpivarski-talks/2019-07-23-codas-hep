{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "# The Scientific Python Ecosystem\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center;\"><b>Who has ever used Python?</b> <i>(Show of hands.)</i></p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center;\"><b>Who has used Python more than C or C++?</b> <i>(Show of hands.)</i></p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center;\"><b>Who has ever used PyROOT?</b> <i>(Show of hands.)</i></p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center;\"><b>Who has ever used Numpy?</b> <i>(Show of hands.)</i></p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center;\"><b>Who has ever used Matplotlib?</b> <i>(Show of hands.)</i></p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center;\"><b>Who has ever used Pandas?</b> <i>(Show of hands.)</i></p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center;\"><b>Who has used Python for machine learning?</b> <i>(Show of hands.)</i></p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "### Part 1: Why Python in particle physics?\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">I could point to its broad adoption as a programming language...</p>\n",
    "\n",
    "<center><img src=\"img/pypl-2019.png\" width=\"75%\"></center>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">But it is more relevant to point to its use in data analysis.</p>\n",
    "\n",
    "<center><img src=\"img/python-r-cpp-googletrends-dataset.png\" width=\"75%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/python-r-cpp-googletrends-machinelearning.png\" width=\"75%\"></center>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">It's hard to overstate the scale of these communities.</p>\n",
    "\n",
    "<center><img src=\"img/root-spark-pandas-google-trends.png\" width=\"75%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.1em\">There is value in adopting popular tools: every question/error message is googlable...</p>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 1.25em\">The growth of Python in astronomy is... astronomical.</p>\n",
    "\n",
    "<table width=\"100%\"><tr style=\"background: white\"><td><img src=\"img/mentions-of-programming-languages.png\" width=\"100%\"></td><td><img src=\"img/ligo-notebook.png\" width=\"100%\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">It's the language of choice for some—but not all—LHC experiments.</p>\n",
    "\n",
    "<img src=\"img/github-cmssw-lin.png\" width=\"100%\">\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">It's the language of choice for some—but not all—LHC experiments.</p>\n",
    "\n",
    "<img src=\"img/github-alice-lin.png\" width=\"100%\">\n",
    "\n",
    "_(Can't measure ATLAS and LHCb because of private repos on GitLab.)_\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"img/commute-by-plane.png\" width=\"60%\"> _(Stolen from Jake Vanderplas.)_\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; font-weight: bold\">Drive to the airport, then take a plane:</p>\n",
    "\n",
    "   * Not everything needs to be fast, only the part that scales with the number of events (or other large number, like number of histogram bins or MC toys).\n",
    "   \n",
    "     The rest of the analysis code is bookkeeping: convenience outweighs speed.\n",
    "     \n",
    "   * Need to step up from interactive tinkering to full-scale analysis __*in small steps*__. Scale-up \"quasistatically\" to avoid a big round of bug-hunting.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: code to compute a fractal (calendar/mousepad/T-shirt...).\n",
    "import time, numpy\n",
    "\n",
    "def run_python(height, width, maxiterations=20):\n",
    "    y, x = numpy.ogrid[-1:0:height*1j, -1.5:0:width*1j]\n",
    "    c = x + y*1j\n",
    "    fractal = numpy.full(c.shape, maxiterations, dtype=numpy.int32)\n",
    "    for h in range(height):\n",
    "        for w in range(width):               # for each pixel (h, w)...\n",
    "            z = c[h, w]\n",
    "            for i in range(maxiterations):   # iterate at most 20 times\n",
    "                z = z**2 + c[h, w]           # applying z → z² + c\n",
    "                if abs(z) > 2:               # if it diverges (|z| > 2)\n",
    "                    fractal[h, w] = i        # color with the iteration number\n",
    "                    break                    # we're done, no need to keep iterating\n",
    "    return fractal\n",
    "\n",
    "starttime = time.time()\n",
    "fractal = run_python(800, 1200)\n",
    "print(\"{0} ns per pixel\".format(1e9 * (time.time() - starttime) / (800 * 1200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty, isn't it?\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(10, 5)); ax.imshow(fractal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMINDER: the original code...\n",
    "\n",
    "\n",
    "def run_python(height, width, maxiterations=20):\n",
    "    y, x = numpy.ogrid[-1:0:height*1j, -1.5:0:width*1j]\n",
    "    c = x + y*1j\n",
    "    fractal = numpy.full(c.shape, maxiterations, dtype=numpy.int32)\n",
    "\n",
    "\n",
    "\n",
    "    for h in range(height):\n",
    "        for w in range(width):               # for each pixel (h, w)...\n",
    "            z = c[h, w]\n",
    "            for i in range(maxiterations):   # iterate at most 20 times\n",
    "                z = z**2 + c[h, w]           # applying z → z² + c\n",
    "                if abs(z) > 2:               # if it diverges (|z| > 2)\n",
    "                    fractal[h, w] = i        # color with the iteration number\n",
    "                    break                    # we're done, no need to keep iterating\n",
    "    return fractal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50× to 100× faster...\n",
    "import numba\n",
    "\n",
    "def run_numba(height, width, maxiterations=20):\n",
    "    y, x = numpy.ogrid[-1:0:height*1j, -1.5:0:width*1j]\n",
    "    c = x + y*1j\n",
    "    fractal = numpy.full(c.shape, maxiterations, dtype=numpy.int32)\n",
    "    return tight_loop(height, width, maxiterations, c, fractal)\n",
    "@numba.jit\n",
    "def tight_loop(height, width, maxiterations, c, fractal):\n",
    "    for h in range(height):\n",
    "        for w in range(width):               # for each pixel (h, w)...\n",
    "            z = c[h, w]\n",
    "            for i in range(maxiterations):   # iterate at most 20 times\n",
    "                z = z**2 + c[h, w]           # applying z → z² + c\n",
    "                if abs(z) > 2:               # if it diverges (|z| > 2)\n",
    "                    fractal[h, w] = i        # color with the iteration number\n",
    "                    break                    # we're done, no need to keep iterating\n",
    "    return fractal\n",
    "\n",
    "starttime = time.time()\n",
    "fractal = run_numba(3200, 4800)\n",
    "print(\"{0} ns per pixel\".format(1e9 * (time.time() - starttime) / (3200 * 4800)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">The \"catch\" is that code in the loop must be purely numerical: arrays and basic number types. In other words, code that doesn't take advantage of \"Pythonness,\" code that would be just as easy to write in C.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">That's what <tt>@numba.jit</tt> does: it compiles the Python function (directly to LLVM and then machine code).</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">So... why not just write C code?</p>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"> If you developed your analysis in interactive Python, in a notebook or command prompt, isolating the numerical part into a function (\"<tt>tight_loop</tt>\" in the previous example) is usually easier than linking to code written in another library.</p>\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 1.25em\">Fully rewriting in C++ isn't a lot faster (30% in this case), but a lot more effort.</p>\n",
    "\n",
    "| Method                                     | time (ns/px) | speedup |\n",
    "|:-------------------------------------------|-------------:|--------:|\n",
    "| Pure Python                                        | 12000   |    1× |\n",
    "| Vectorized Numpy                                   |   368   |   30× |\n",
    "| Vectorized CuPy (run on GPU)                       |    81   |  150× |\n",
    "| **Compiled by Numba**                                  |   **136**   |   **90×** |\n",
    "| Compiled & parallelized by Numba                   |    45   |  250× |\n",
    "| Compiled & run on GPU by Numba                     |     7.8 | 1500× |\n",
    "| Parallelized by Dask                               |   238   |   50× |\n",
    "| Parallelized by Dask, compiled by Numba            |    48   |  250× |\n",
    "| Partially rewritten in Cython (Python/C++ hybrid)  |  1485   |    8× |\n",
    "| **Completely rewritten in Cython (pure C++)**          |    **99**   |  **120×** |\n",
    "| **Completely rewritten in pybind11 (pure C++)**        |    **98**   |  **120×** |\n",
    "| Completely rewritten in ROOT (pure C++ with `-O0`) |   379   |   32× |\n",
    "\n",
    "_(See [misc-fractal.ipynb](misc-fractal.ipynb) for a derivation of the above.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Drive/bike/skateboard on your daily commute:</b> do exploration and problem-solving in Python because it has simple data structures, doesn't seg-fault, and dumps stack traces...</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Fly to Europe:</b> optimize the loop that scales with big numbers so that you can finish analyzing your 100 TB this year...</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: right; margin-right: 10%\">... by replacing critical code <i><b>in small steps</b></i>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<center><img src=\"img/numpy-logo.png\" width=\"35%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Numpy is the common (in-memory) data format for scientific Python.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Nearly every package can input/output data as Numpy arrays.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Numpy also has a suite of functions for doing calculations a whole array at a time: a <b>S</b>ingle (Python) <b>I</b>nstruction on <b>M</b>ultiple <b>D</b>ata.</p>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy arrays of physics data:\n",
    "import uproot\n",
    "arrays = uproot.open(\"data/Zmumu.root\")[\"events\"].arrays(namedecode=\"utf-8\")\n",
    "\n",
    "print(\"Names of arrays in this dict:\\n\")\n",
    "print(list(arrays), \"\\n\\n\")\n",
    "\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take arrays out of the dict and make each one a variable.\n",
    "for n in arrays:\n",
    "    exec(f\"{n} = arrays['{n}']\")\n",
    "\n",
    "# Example array: energy of first muon in each event\n",
    "E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pT of all muon pairs:\n",
    "\n",
    "import numpy\n",
    "\n",
    "pt = numpy.sqrt((px1 + px2)**2 + (py1 + py2)**2)\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And __LOOK__:\n",
    "\n",
    "matplotlib.pyplot.hist(pt, bins=100, range=(0, 200));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute p of all muon pairs:\n",
    "\n",
    "p = numpy.sqrt(pt**2 + (pz1 + pz2)**2)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And __LOOK__:\n",
    "\n",
    "matplotlib.pyplot.hist(p, bins=100, range=(0, 500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mass of all muon pairs:\n",
    "\n",
    "mass = numpy.sqrt((E1 + E2)**2 - p**2)\n",
    "mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And __LOOK__:\n",
    "\n",
    "matplotlib.pyplot.hist(mass, bins=100, range=(0, 120));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start adding cuts, exploring different regions, etc.\n",
    "\n",
    "matplotlib.pyplot.hist(mass[Q1 != Q2], bins=100, range=(0, 120));\n",
    "matplotlib.pyplot.hist(mass[Q1 == Q2], bins=100, range=(0, 120));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">This is the point: you calculate <i>one thing</i> and then you <i>LOOK</i> at the result.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Array-at-a-time logic gives you a statistical view of each <i>step</i> in your calculation as you develop it.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">It's not always about the speed; sometimes it's about the interactivity.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As physicists, we know this. That's why we have TTree-at-a-time operations.\n",
    "\n",
    "import ROOT\n",
    "canvas = ROOT.TCanvas(\"canvas\", \"\", 400, 300)\n",
    "file = ROOT.TFile(\"data/Zmumu.root\")\n",
    "tree = file.Get(\"events\")\n",
    "tree.Draw(\"sqrt((E1 + E2)**2 - (px1 + px2)**2 - (py1 + py2)**2 - (pz1 + pz2)**2)\")\n",
    "canvas.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">The hard part is turning those <tt>TTree::Draw</tt> expressions into a full analysis.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">How many of you have started with <tt>TTree::Draw</tt> and had to rewrite everything as a C++ loop?</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Our goal is to do initial exploration in a convenient way and then scale up without having to change everything.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "### Part 2: There's an app for that\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/shells-1.png\" width=\"80%\">\n",
    "\n",
    "<i>(Stolen from Jake Vanderplas.)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/shells-2.png\" width=\"80%\">\n",
    "\n",
    "<i>(Stolen from Jake Vanderplas.)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/shells-3.png\" width=\"80%\">\n",
    "\n",
    "<i>(Stolen from Jake Vanderplas.)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/shells-4.png\" width=\"80%\">\n",
    "\n",
    "<i>(Stolen from Jake Vanderplas.)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/shells-5.png\" width=\"80%\">\n",
    "\n",
    "<i>(Stolen from Jake Vanderplas.)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Much of what we do, as physicists, are not new problems. You can learn a lot by attempting to write an algorithm yourself, but eventually you'll want to plug together functions from established libraries (that you understand!).</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Wikipedia</b> (to learn the names of things) + <b>StackOverflow</b> (to find common solutions) is a good way to develop analysis code.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Most of these solutions come in Numpy-shaped pieces.</p>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 100px\"><img src=\"img/scipy-logo.png\" width=\"45%\" style=\"vertical-align: middle\"> = <img src=\"img/numerical-recipes.jpg\" width=\"25%\" style=\"vertical-align: middle\"></p>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">SciPy was originally the \"all in one\" scientific package, but today, much of the development is beyond SciPy.</p>\n",
    "\n",
    "| Date | Development |\n",
    "|:----:|:-----|\n",
    "| 1994 | **Python** 1.0 released. |\n",
    "| 1995 | **Numeric** was the first array package (a.k.a. Numerical, Numerical Python, Numpy). |\n",
    "| 2001 | **SciPy** gathered scientific functions into one codebase, including **Numeric**. |\n",
    "| 2003 | **Matplotlib** released (at that time, one of many plotters... R.I.P. **Biggles**). |\n",
    "| 2003 | **Numarray** introduced as a competitor to **Numeric** with more features (memory-mapped files, alignment, record arrays). |\n",
    "| 2005 | **Numpy** unified features of **Numeric** and **Numarray** and became the common array library. |\n",
    "| 2008 | **Pandas** first released. |\n",
    "| 2010 | **Scikit-Learn** first released. |\n",
    "| 2011 | **AstroPy** first released. |\n",
    "| 2012 | **Anaconda** first released. |\n",
    "| 2014 | **Jupyter** first released. |\n",
    "| 2015 | **Keras** first released. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/scipy-docs.png\" width=\"80%\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "?scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?scipy.stats.crystalball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.linspace(-10, 10, 100)\n",
    "y = scipy.stats.crystalball.pdf(x, beta=0.5, m=3)     # logpdf, cdf\n",
    "\n",
    "matplotlib.pyplot.plot(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.crystalball.rvs(beta=0.5, m=3, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = uproot.open(\"data/Zmumu.root\")[\"events\"].array(\"M\")\n",
    "\n",
    "y, edges = numpy.histogram(masses, bins=100)\n",
    "yerr = numpy.sqrt(y)\n",
    "\n",
    "# the middle of each bin\n",
    "x = (edges[1:] + edges[:-1])/2\n",
    "\n",
    "matplotlib.pyplot.errorbar(x, y, yerr, fmt=\"o\", capsize=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "def f(x, a, b, c, d):\n",
    "    return a*scipy.stats.cauchy.pdf(x, b, c) + d/x**2\n",
    "\n",
    "parameters, errors = scipy.optimize.curve_fit(f, x[y > 0], y[y > 0], sigma=yerr[y > 0])  # exclude y == 0\n",
    "\n",
    "matplotlib.pyplot.plot(x, f(x, *parameters))\n",
    "matplotlib.pyplot.errorbar(x, y, yerr, fmt=\"o\", capsize=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Five minute challenge:</b> using only commands from the previous cell, plot the fit residuals.</p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/iminuit.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iminuit\n",
    "\n",
    "def chi2(a, b, c, d):\n",
    "    return ((y[y > 0] - f(x[y > 0], a, b, c, d))**2 / yerr[y > 0]**2).sum()\n",
    "\n",
    "m = iminuit.Minuit(chi2, errordef=1,\n",
    "                   a=3350, b=91, c=2, d=30,\n",
    "                   error_a=100, error_b=1, error_c=0.1, error_d=10)\n",
    "m.migrad()\n",
    "m.hesse()\n",
    "m.minos()\n",
    "m.draw_mncontour(\"a\", \"b\", nsigma=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<center><img src=\"img/scikit-learn-logo.png\" width=\"40%\"></center>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">To branch out in a modular way, SciPy introduced the idea of \"SciKits\"—separate packages from SciPy that have a similar interface.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">The most famous of these is Scikit-Learn, a package that gathered all machine learning algorithms under one roof—just before the deep learning revolution...</p>\n",
    "\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/scikit-learn-estimators.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "X1, y1 = sklearn.datasets.make_gaussian_quantiles(\n",
    "    cov=2.0, n_samples=800, n_features=2, n_classes=2, random_state=1)\n",
    "X2, y2 = sklearn.datasets.make_gaussian_quantiles(\n",
    "    mean=(3, 3), cov=1.5, n_samples=1200, n_features=2, n_classes=2, random_state=1)\n",
    "X = numpy.concatenate((X1, X2))\n",
    "y = numpy.concatenate((y1, -y2 + 1))\n",
    "\n",
    "# Example of a hard classification problem.\n",
    "matplotlib.pyplot.scatter(X[y == 0, 0], X[y == 0, 1], c=\"deepskyblue\", edgecolor=\"k\");\n",
    "matplotlib.pyplot.scatter(X[y == 1, 0], X[y == 1, 1], c=\"orange\", edgecolor=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "\n",
    "# Example model: decision tree classifier\n",
    "model = sklearn.tree.DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "# Consistent interface: nearly every model has a fit method with this signature\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"predictions:\\n\", model.predict(X))\n",
    "print(\"truth:\\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "# Another model: boosted decision tree\n",
    "model = sklearn.ensemble.AdaBoostClassifier(\n",
    "    sklearn.tree.DecisionTreeClassifier(max_depth=2), algorithm=\"SAMME\", n_estimators=100)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"predictions:\\n\", model.predict(X))\n",
    "print(\"truth:\\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = numpy.meshgrid(numpy.arange(-5, 8, 0.02), numpy.arange(-5, 8, 0.02))\n",
    "Z = model.predict(numpy.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Overlay the training points on the decision boundary.\n",
    "matplotlib.pyplot.contourf(xx, yy, Z);\n",
    "matplotlib.pyplot.scatter(X[y == 0, 0], X[y == 0, 1], c=\"deepskyblue\", edgecolor=\"k\", alpha=0.2);\n",
    "matplotlib.pyplot.scatter(X[y == 1, 0], X[y == 1, 1], c=\"orange\", edgecolor=\"k\", alpha=0.2);\n",
    "matplotlib.pyplot.xlim(-5, 8);\n",
    "matplotlib.pyplot.ylim(-5, 8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">Notice that we have the same Numpy interfaces everywhere, and everything acts one array at a time, rather than one value at a time.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">The new deep learning frameworks define their own array types (e.g. PyTorch tensors, TensorFlow tensors), but these are very similar to Numpy arrays, with the addition that they can move data to and from GPUs.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/scikit-hep-page.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Example 1:</b> pyjet, a Numpythonic wrapper for FastJet</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make a fake-o Monte Carlo: three clusters at specified central values\n",
    "fourvectors = numpy.empty(1000, dtype=[(\"E\", float), (\"px\", float),\n",
    "                                       (\"py\", float), (\"pz\", float)])\n",
    "indexes = numpy.random.randint(0, 3, 1000)\n",
    "\n",
    "#                        i   pt   eta    phi\n",
    "for i, pt, eta, phi in [(0, 0.5,  0.5,     0),   # cluster center 0\n",
    "                        (1, 0.2, -0.8,  1.57),   # cluster center 1\n",
    "                        (2, 0.1,  0.3, -1.57)]:  # cluster center 2\n",
    "    this = (indexes == i)\n",
    "    pt = abs(numpy.random.normal(pt, 0.1, this.sum()))\n",
    "    eta = numpy.random.normal(eta, 0.03, this.sum())\n",
    "    phi = numpy.random.normal(phi, 0.3, this.sum())\n",
    "    fourvectors[\"px\"][this] = px = (pt*numpy.cos(phi)*numpy.cosh(eta))\n",
    "    fourvectors[\"py\"][this] = py = (pt*numpy.sin(phi)*numpy.cosh(eta))\n",
    "    fourvectors[\"pz\"][this] = pz = (pt*numpy.sinh(eta))\n",
    "    fourvectors[\"E\"][this]  = numpy.sqrt(px**2 + py**2 + pz**2)\n",
    "\n",
    "fourvectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyjet\n",
    "\n",
    "# This is FastJet, running in C++.\n",
    "# \n",
    "# By passing all particles, array-at-a-time, we avoid Python's slowness.\n",
    "\n",
    "clustering = pyjet.cluster(fourvectors, R=1.0, p=-1, ep=True)\n",
    "clustering.inclusive_jets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Example 2:</b> particle, an interface to Particle Data Tables</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import particle\n",
    "from hepunits.units import cm\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "# Find all strange baryons with c*tau > 1 cm\n",
    "for x in particle.Particle.findall(lambda p:\n",
    "    p.pdgid.is_baryon and p.pdgid.has_strange and p.width > 0 and p.ctau > 1 * cm):\n",
    "    \n",
    "    IPython.display.display(IPython.display.Latex(\"$\" + x.latex_name + \"$\"))\n",
    "    print(repr(x), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\"><b>Example 3:</b> pyhf, limit-setting similar to HistFactory and CmsCombine</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf                                                        # (scale to 125%)\n",
    "import awkward\n",
    "\n",
    "s, b, obs = [[0.0, 0.0, 0.1, 0.2, 0.5, 1.0, 1.8, 2.7, 2.0, 0.3],   # signal peaks around bin 8\n",
    "             [6.0, 5.5, 4.5, 3.8, 3.3, 2.6, 2.0, 1.8, 1.5, 1.0],   # background steadily falls\n",
    "             [  6,   7,   4,   4,   4,   3,   4,   3,   4,   0]]   # observations perfer 3/4 signal\n",
    "model = pyhf.simplemodels.hepdata_like(signal_data=s, bkg_data=b, bkg_uncerts=numpy.sqrt(b).tolist())\n",
    "def hypotest(mu):\n",
    "    return pyhf.utils.hypotest(mu, obs + model.config.auxdata, model, return_expected_set=True)\n",
    "\n",
    "mus = numpy.linspace(0, 2, 30)\n",
    "CLs = awkward.fromiter([hypotest(mu) for mu in mus])\n",
    "CLs_observed = CLs[:, 0, 0]                                        # mucking around with indexes\n",
    "CLs_minus2, CLs_minus1, CLs_expected, CLs_plus1, CLs_plus2 = [CLs[:, 1, i, 0] for i in range(5)]\n",
    "\n",
    "matplotlib.pyplot.fill_between(mus, CLs_minus2, CLs_plus2, facecolor=\"yellow\");\n",
    "matplotlib.pyplot.fill_between(mus, CLs_minus1, CLs_plus1, facecolor=\"limegreen\");\n",
    "matplotlib.pyplot.plot(mus, CLs_expected, c=\"black\", linestyle=\"dotted\");\n",
    "matplotlib.pyplot.plot(mus, CLs_observed, c=\"black\", marker=\"o\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "### Part 3: ROOT data in Python\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT                                   # PyROOT\n",
    "\n",
    "file = ROOT.TFile(\"data/HZZ-objects.root\")    # PyROOT transliterates C++ to Python\n",
    "tree = file.Get(\"events\")\n",
    "\n",
    "canvas = ROOT.TCanvas(\"canvas\", \"\", 400, 300) # JupyROOT only: must create TCanvas\n",
    "tree.Draw(\"muonp4.Pt()\")\n",
    "canvas.Draw()                                 # and Draw it to see plots inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyROOT can iterate over the data directly, in a Python-friendly way.\n",
    "\n",
    "for i, event in enumerate(tree):\n",
    "    print(\"event\", i)\n",
    "    for muon in event.muonp4:\n",
    "        print(repr(muon), muon.Pt())\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">But be forewarned: PyROOT was not made to be used in a loop over big data. (Actually, it's as much slower than Python as Python is from C++.)</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">You can start this way, but if you'll be analyzing TB of data, you'll have to rewrite your code.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">We want to explore data in a way that doesn't have to be completely rewritten for speed.</p>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyROOT's new AsMatrix method gives you Numpy arrays directly (loops run in C++).\n",
    "\n",
    "tree.AsMatrix([\"eventweight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But it's only for purely numeric data, not objects...\n",
    "\n",
    "tree.AsMatrix([\"MET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and not variable number of values per event, like vector<float>\n",
    "\n",
    "tree.AsMatrix([\"muoniso\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT's new preferred way of processing TTrees is called RDataFrame.\n",
    "# You can define a dataflow in Python with C++ in strings (convenient!).\n",
    "\n",
    "rdf = ROOT.RDataFrame(\"events\", \"data/HZZ-objects.root\")\n",
    "h = (rdf.Filter(\"muonp4.size() >= 2\")\n",
    "        .Define(\"zmass\", r\"\"\"(muonp4[0] + muonp4[1]).M()\"\"\")\n",
    "        .Histo1D((\"\", \"\", 120, 0, 120), \"zmass\"))\n",
    "h.Draw(); canvas.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And you can get the result of this dataflow as Numpy arrays (even better!).\n",
    "\n",
    "array = (rdf.Filter(\"muonp4.size() >= 2\")\n",
    "            .Define(\"zmass\", r\"\"\"(muonp4[0] + muonp4[1]).M()\"\"\")\n",
    "            .AsNumpy(columns=[\"zmass\"]))\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also get arrays of objects and arrays of vectors of objects.\n",
    "\n",
    "array = rdf.AsNumpy(columns=[\"muonp4\"])[\"muonp4\"]\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But looping over them is back to PyROOT. The array is an array of PyROOT objects.\n",
    "\n",
    "for i, event in enumerate(array):\n",
    "    print(\"event\", i)\n",
    "    for muon in event:\n",
    "        print(repr(muon), muon.Pt())\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">To get efficient processing in ROOT, you have to do the heavy work in C++. That's just how it works. What's new is that the C++ can be expressed as inline strings in Python.</p>\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em\">uproot is an alternative ROOT I/O implemented in Python + Numpy (i.e. it's pip-installable).</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/abstraction-layers.png\" width=\"80%\"></center>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "file = uproot.open(\"data/HZZ-objects.root\")\n",
    "tree = file[\"events\"]\n",
    "\n",
    "array = tree.array(\"muonp4\")\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although this looks like an array of variable-length arrays of TLorentzVectors,\n",
    "# it's implmented in terms of columnar arrays, not objects.\n",
    "print(array.layout)\n",
    "print(f\"\\narray for TLorentzVector.fX:\\n{array.layout[2, 0, 4].array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the interface is array-at-a-time: neither for loops nor call-outs to C++.\n",
    "\n",
    "good_events = (array.counts >= 2)\n",
    "print(f\"good_events: {good_events}\")\n",
    "\n",
    "first  = array[good_events, 0]\n",
    "second = array[good_events, 1]\n",
    "print(f\"\\nfirst:       {first}\")\n",
    "print(f\"second:      {second}\")\n",
    "\n",
    "z_candidates = first + second\n",
    "print(f\"\\nz_mass:      {z_candidates.mass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 1.25em; text-align: center\">Which one should you use?</p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 2em; font-weight: bold; text-align: center\">Both!</p>\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
